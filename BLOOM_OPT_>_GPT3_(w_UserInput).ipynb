{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install openai -q"
      ],
      "metadata": {
        "id": "Se3vZs4BAnPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f76ed090-f8e9-4521-e5f1-e416b5cd2dc1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███████▎                        | 10 kB 22.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 20 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 30 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 40 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 44 kB 712 kB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 146 kB 26.9 MB/s \n",
            "\u001b[?25h  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers -q"
      ],
      "metadata": {
        "id": "AzRc7tViq6fS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "272e2a88-ced6-4b83-bd00-55b4e3c0d35e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.8 MB 15.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 54.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 60.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T1N1ozAb_xe_"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n"
      ],
      "metadata": {
        "id": "xysgtCMdAb1C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed, GPT2Tokenizer, OPTForCausalLM"
      ],
      "metadata": {
        "id": "x8x7B-x1rFjq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelChoice = input(\"Please choose a first layer model to use (BLOOM or OPT): \")\n",
        "modelChoice = modelChoice.lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOoITJlexYoU",
        "outputId": "f10204ce-e7e8-47a0-dfb0-48d620749ddd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please choose a first layer model to use (BLOOM or OPT): OPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "if modelChoice == \"bloom\":\n",
        "  # BLOOM\n",
        "  print(\"You have chosen BLOOM!\")\n",
        "  model = AutoModelForCausalLM.from_pretrained('bigscience/bloom-1b7', use_cache=True)\n",
        "  tokenizer = AutoTokenizer.from_pretrained('bigscience/bloom-1b7')\n",
        "elif modelChoice == \"opt\":\n",
        "  # # OPT\n",
        "  print(\"You have chosen OPT!\")\n",
        "  model = OPTForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(\"facebook/opt-350m\")\n",
        "else:\n",
        "  print(\"You have mistyped the model choice input. Please rerun the previous cell!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHbHyl9orK13",
        "outputId": "38731f31-2ff3-4ea0-d21d-fe7f6756d6da"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have chosen OPT!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(424242)"
      ],
      "metadata": {
        "id": "_hla60hGrPPk"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"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\"\n"
      ],
      "metadata": {
        "id": "UxJgsMhOAu5x"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_inp = input(\"What is your self-description? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcH2LUoiIA_Y",
        "outputId": "096c6687-ed14-41e5-e0d1-21b598cf5469"
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is your self-description? Software Engineer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = user_inp\n",
        "# print(prompt)\n",
        "inputids = tokenizer(prompt, return_tensors='pt').to(0)\n",
        "sample = model.generate(**inputids, max_length=300, num_beams = 10, num_beam_groups = 10, top_k = 1, temperature = 0.9, repetition_penalty = 3.5, diversity_penalty = 2.0)\n",
        "          \n",
        "gpt3prompt = tokenizer.decode(sample[0], truncate_before_pattern=[r\"\\n\\n^#$\", \"^'''\", \"\\n\\n\\n\"])\n",
        "print(gpt3prompt)\n",
        "\n",
        "response = openai.Completion.create(engine=\"text-davinci-003\", prompt=\"Build a full professional resume from the following summary: \" + gpt3prompt + \"\\nResume\", \n",
        "                                    max_tokens=2500, top_p = 1, best_of = 5, presence_penalty=1.5)\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "id": "6SWOqzfbA0RD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a00a545-10d5-4e1a-baa3-f15210e88dd2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "</s>Software Engineer at Google\n",
            "I'm a software engineer. I've been working on this for about 2 years now, and it's really fun.  It's not easy to get into but once you do, it's worth it. You can't go wrong with the experience!\n",
            "What kind of work are you doing? What type of projects/projects have you done? How long have you been in tech? Do you have any tips or tricks for people who want to start their own company?</s>\n",
            "\n",
            "\n",
            "Jenny Smith\n",
            "Software Engineer \n",
            "Google, Inc. | 2 Years\n",
            "\n",
            "Summary of Qualifications:\n",
            "\n",
            "• Highly experienced software engineer with two years of experience in Google working on a variety of projects. \n",
            "• Skilled in programming, debugging, and troubleshooting complex systems as well as developing new applications. \n",
            "• Possesses excellent communication and problem solving skills, offering expertise to colleagues in the tech field. \n",
            "• Demonstrates acute attention to detail when coding and designing software solutions, providing accurate and timely results.\n",
            "\n",
            "Key Projects Completed:\n",
            "\n",
            "• Developed innovative web-based platform that allowed remote access to business intelligence reports. \n",
            "• Implemented a backend caching system for optimized performance for large data sets. \n",
            "• Created an automated process to update legacy software in order to more effectively manage customer accounts and contact information.\n",
            "\n",
            "Technical Experience:\n",
            "\n",
            "Programming Languages: Java, JavaScript, Python, SQL\n",
            "Frameworks & Libraries: Spring Boot, React.js, Vue.js, Angular\n",
            "Operating Systems: Windows, Linux, MacOS \n",
            "Technologies: CI/CD pipelines, REST APIs, DevOps Tools\n",
            "\n",
            "Work History:\n",
            "\n",
            "Software Engineer, Google, Inc., 2018-2020\n",
            "• Analyzed user requirements and implemented features according to specifications. \n",
            "• Debugged, tested, and maintained source code to ensure appropriate functioning within application programs. \n",
            "• Wrote technical documents to support product development and updated existing documents to reflect changes during the design phase. \n",
            "• Used Git version control to maintain project records and monitor progress.\n",
            "\n",
            "Tips/Tricks for Starting Your Own Company:\n",
            "• Utilize available resources such as local libraries and coworking spaces. \n",
            "• Reach out to established entrepreneurs in your network and ask questions. \n",
            "• Consider hiring a coach or mentor to provide guidance and advice. \n",
            "• Build up your contacts through attending events, conferences, and seminars. \n",
            "• Establish effective market analysis strategies to understand customer needs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FQOC8VUlvfyW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}