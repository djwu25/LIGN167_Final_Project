{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPve5lvGc0qcXUodyXZdQb8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djwu25/LIGN167_Final_Project/blob/main/Small_Prompt_OPT_%3EGPT3Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-pbWSD4_4_p",
        "outputId": "09241337-28b2-4ae3-e4d0-bb280f55ee92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███████▎                        | 10 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 20 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 30 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 40 kB 37.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 44 kB 2.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 146 kB 67.6 MB/s \n",
            "\u001b[?25h  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "pip install openai -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwniITMPAL80",
        "outputId": "8c1ee090-21a1-4d7b-e8d1-629b7e127556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.8 MB 29.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 62.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 56.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from transformers import GPT2Tokenizer, OPTForCausalLM\n",
        "import torch\n",
        "\n",
        "# Open AI Key\n",
        "openai.api_key = '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'\n",
        "\n",
        "# OPT\n",
        "model = OPTForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"facebook/opt-350m\")\n",
        "\n",
        "# Inputs Eduction\n",
        "education_prompt = 'Software Engineer'\n",
        "\n",
        "# Use OPT Model\n",
        "education_inputs = tokenizer.encode(education_prompt, return_tensors=\"pt\")\n",
        "education_output = model.generate(education_inputs, max_length=70, num_beams=10, num_beam_groups=10, top_k=1,\n",
        "                        temperature=0.9, repetition_penalty=3.5, diversity_penalty=2.0)\n",
        "\n",
        "# Print Result\n",
        "gpt3_education = tokenizer.decode(education_output[0], truncate_before_pattern=[r\"\\n\\n^#$\", \"^'''\", \"\\n\\n\\n\"])\n",
        "#print(gpt3_education)\n",
        "\n",
        "# GPT3\n",
        "education_response = openai.Completion.create(engine=\"text-davinci-003\", prompt= 'Build an education section of a resume with the given information: ' + gpt3_education + \"\\nResult:\", \n",
        "                                    max_tokens=1500, top_p = 1, best_of=5, presence_penalty=1.5)\n",
        "education_result = education_response.choices[0].text\n",
        "\n",
        "# Inputs Job Position 1\n",
        "job_pos_1_prompt = 'Backend Engineer at Tesla'\n",
        "\n",
        "# Use OPT Model\n",
        "job_pos_1_inputs = tokenizer.encode(job_pos_1_prompt, return_tensors=\"pt\")\n",
        "job_pos_1_output = model.generate(job_pos_1_inputs, max_length=70, num_beams=10, num_beam_groups=10, top_k=1,\n",
        "                        temperature=0.9, repetition_penalty=3.5, diversity_penalty=2.0)\n",
        "\n",
        "# Print Result\n",
        "gpt3_job_pos_1 = tokenizer.decode(job_pos_1_output[0], truncate_before_pattern=[r\"\\n\\n^#$\", \"^'''\", \"\\n\\n\\n\"])\n",
        "#print(gpt3_job_pos_1)\n",
        "\n",
        "# Inputs Job Position 2\n",
        "job_pos_2_prompt = 'Front-End Website Developer at Google'\n",
        "\n",
        "# Use OPT Model\n",
        "job_pos_2_inputs = tokenizer.encode(job_pos_2_prompt, return_tensors=\"pt\")\n",
        "job_pos_2_output = model.generate(job_pos_2_inputs, max_length=70, num_beams=10, num_beam_groups=10, top_k=1,\n",
        "                        temperature=0.9, repetition_penalty=3.5, diversity_penalty=2.0)\n",
        "\n",
        "# Print Result\n",
        "gpt3_job_pos_2 = tokenizer.decode(job_pos_2_output[0], truncate_before_pattern=[r\"\\n\\n^#$\", \"^'''\", \"\\n\\n\\n\"])\n",
        "#print(gpt3_job_pos_1)\n",
        "\n",
        "# Project Input GPT3\n",
        "gpt3_job_pos_input = gpt3_job_pos_1 + gpt3_job_pos_2\n",
        "\n",
        "# GPT3\n",
        "job_pos_response = openai.Completion.create(engine=\"text-davinci-003\", prompt= 'Build a work experience section, with bullet points, of a resume with the given information: ' + gpt3_job_pos_input + \"\\nResult:\", \n",
        "                                    max_tokens=1700, top_p = 1, best_of=5, presence_penalty=1.5)\n",
        "job_pos_result = job_pos_response.choices[0].text\n",
        "\n",
        "# Inputs Project 1\n",
        "project_1_prompt = 'Website project as front end css developer'\n",
        "\n",
        "# Use OPT Model\n",
        "project_1_inputs = tokenizer.encode(project_1_prompt, return_tensors=\"pt\")\n",
        "project_1_output = model.generate(project_1_inputs, max_length=70, num_beams=10, num_beam_groups=10, top_k=1,\n",
        "                        temperature=0.9, repetition_penalty=3.5, diversity_penalty=2.0)\n",
        "\n",
        "# Print Result\n",
        "gpt3_project_1 = tokenizer.decode(project_1_output[0], truncate_before_pattern=[r\"\\n\\n^#$\", \"^'''\", \"\\n\\n\\n\"])\n",
        "#print(gpt3_job_pos_1)\n",
        "\n",
        "# Inputs Project 2\n",
        "project_2_prompt = 'School Programming project in Java'\n",
        "\n",
        "# Use OPT Model\n",
        "project_2_inputs = tokenizer.encode(project_2_prompt, return_tensors=\"pt\")\n",
        "project_2_output = model.generate(project_2_inputs, max_length=70, num_beams=10, num_beam_groups=10, top_k=1,\n",
        "                        temperature=0.9, repetition_penalty=3.5, diversity_penalty=2.0)\n",
        "\n",
        "# Print Result\n",
        "gpt3_project_2 = tokenizer.decode(project_2_output[0], truncate_before_pattern=[r\"\\n\\n^#$\", \"^'''\", \"\\n\\n\\n\"])\n",
        "#print(gpt3_job_pos_1)\n",
        "\n",
        "# Project Input GPT3\n",
        "gpt3_project_input = gpt3_project_1 + gpt3_project_2\n",
        "\n",
        "# GPT3\n",
        "project_response = openai.Completion.create(engine=\"text-davinci-003\", prompt= 'Build a project experience section, with bullet points, of a resume with the given information: ' + gpt3_project_input + \"\\nResult:\", \n",
        "                                    max_tokens=1700, top_p = 1, best_of=5, presence_penalty=1.5)\n",
        "project_result = project_response.choices[0].text\n",
        "\n",
        "#print(job_pos_1_result)\n",
        "final_resume = education_result + \"\\n\" + job_pos_result + \"\\n\" + project_result\n",
        "print(final_resume)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmEzqC8LASlU",
        "outputId": "96af4e41-a4e9-4f58-ae26-fc979b9a8718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Education:\n",
            "• University of New York, NY | Bachelor of Science in Computer Science | 1998-2002 \n",
            "• Microsoft Certified Solutions Associate | 2017 \n",
            "• Certified Scrum Master | 2018 \n",
            "• Google Cloud Platform Professional Data Engineer | 2019\n",
            " \n",
            "• Google, Front-End Web Developer (2 years): Developed and maintained front-end web applications using HTML5, CSS3, JavaScript, PHP, MySQL, MongoDB, PostgreSQL, SQLite, Node.js, Ruby on Rails, Python, Java and C. \n",
            "• Tesla (NASDAQ:TSLA), Backend Engineer: Worked on backend engineering projects for over 1 million vehicles around the world with an estimated 2,000 employees. Utilized my knowledge in administration of databases, server-side programming languages and web development.\n",
            "\n",
            "- Developed a web application with Java, C++, Python, and Ruby for students to learn how to code.\n",
            "- Utilized front end CSS to build a simple, clean, and easy to navigate website.\n",
            "- Participated in 2 year programming project while attending University of California, Berkeley.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DXH00zIjA7yO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}